"use strict";
var __assign = (this && this.__assign) || function () {
    __assign = Object.assign || function(t) {
        for (var s, i = 1, n = arguments.length; i < n; i++) {
            s = arguments[i];
            for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p))
                t[p] = s[p];
        }
        return t;
    };
    return __assign.apply(this, arguments);
};
Object.defineProperty(exports, "__esModule", { value: true });
var constants_1 = require("../constants");
var lodash_1 = require("lodash");
var token_types_1 = require("../constants/token-types");
var data_structures_1 = require("../utils/data-structures");
var Tokenizer = /** @class */ (function () {
    /**
     * @param {Object} cfg
     *  @param {String[]} cfg.reservedWords Reserved words in SQL
     *  @param {String[]} cfg.reservedToplevelWords Words that are set to new line separately
     *  @param {String[]} cfg.reservedNewlineWords Words that are set to newline
     *  @param {String[]} cfg.stringTypes String types to enable: "", '', ``, [], N''
     *  @param {String[]} cfg.openParens Opening parentheses to enable, like (, [
     *  @param {String[]} cfg.closeParens Closing parentheses to enable, like ), ]
     *  @param {String[]} cfg.indexedPlaceholderTypes Prefixes for indexed placeholders, like ?
     *  @param {String[]} cfg.namedPlaceholderTypes Prefixes for named placeholders, like @ and :
     *  @param {String[]} cfg.lineCommentTypes Line comments to enable, like # and --
     *  @param {String[]} cfg.specialWordChars Special chars that can be found inside of words, like @ and #
     */
    function Tokenizer(cfg) {
        var _this = this;
        /**
         * Takes a SQL string and breaks it into tokens.
         * Each token is an object with type and value.
         *
         * @param {String} input The SQL string
         * @return {Object[]} tokens An array of tokens.
         *  @return {String} token.type
         *  @return {String} token.value
         */
        this.tokenize = function (input) {
            var token = { type: '', value: '' };
            var tokens = new data_structures_1.LinkedList();
            // Keep going till the end of the string
            while (input.length) {
                // Get the next token
                var tmp = _this.getNextToken(input, token);
                if (tmp) {
                    token = tmp;
                    tokens.append(token);
                    input = input.substring(token.value.length);
                }
            }
            return tokens;
        };
        this.getNextToken = function (input, prev) {
            var regexes = _this.getRegexes(input, prev);
            var sorted = Object.keys(regexes).sort();
            var result = false;
            for (var id in sorted) {
                var definition = regexes[id];
                result = Tokenizer.matchRegex(definition);
                if (result) {
                    break;
                }
            }
            return result;
        };
        this.getRegexes = function (input, prev) {
            return {
                0: {
                    input: input,
                    type: token_types_1.default.DBT_START_VAR,
                    regex: /\{\s?\{\s?/,
                    description: 'Finds start of a dbt/jinja variable.',
                },
                1: {
                    input: input,
                    type: token_types_1.default.DBT_END_VAR,
                    regex: /\s?\}\s?\}/,
                    description: 'Finds end of a dbt/jinja variable.',
                },
                2: {
                    input: input,
                    type: token_types_1.default.DBT_START_TEMPLATE,
                    regex: /\s?\{\s?\%\-?/,
                    description: 'Finds start of a dbt/jinja template/macro.',
                },
                3: {
                    input: input,
                    type: token_types_1.default.DBT_END_TEMPLATE,
                    regex: /\-?\%\s?\}/,
                    description: 'Finds end of a dbt/jinja template/macro.',
                },
                4: {
                    input: input,
                    type: token_types_1.default.DBT_START_MARKERS,
                    regex: Tokenizer.createMultiWordRegex(constants_1.DbtConfig.startMarkers),
                    description: 'Finds start marker words in template/macro.',
                },
                5: {
                    input: input,
                    type: token_types_1.default.DBT_END_MARKERS,
                    regex: Tokenizer.createMultiWordRegex(constants_1.DbtConfig.endMarkers),
                    description: 'Finds end marker words in template/macro.',
                },
                6: {
                    input: input,
                    type: token_types_1.default.WHITESPACE,
                    regex: /^(\s+)/,
                },
                7: {
                    input: input,
                    type: token_types_1.default.LINE_COMMENT,
                    regex: Tokenizer.createLineCommentRegex(_this.cfg.lineCommentTypes),
                },
                8: {
                    input: input,
                    type: token_types_1.default.BLOCK_COMMENT,
                    regex: /^(\/\*[^]*?(?:\*\/|$))/,
                },
                9: {
                    input: input,
                    type: token_types_1.default.STRING,
                    regex: Tokenizer.createStringRegex(_this.cfg.stringTypes),
                },
                10: {
                    input: input,
                    type: token_types_1.default.OPEN_PAREN,
                    regex: Tokenizer.createParenRegex(_this.cfg.openParens),
                },
                11: {
                    input: input,
                    type: token_types_1.default.CLOSE_PAREN,
                    regex: Tokenizer.createParenRegex(_this.cfg.closeParens),
                },
                12: {
                    input: input,
                    type: token_types_1.default.PLACEHOLDER,
                    regex: Tokenizer.createPlaceholderRegex(_this.cfg.namedPlaceholderTypes, '[a-zA-Z0-9._$]+'),
                    parseFunc: function (v) { return v.slice(1); },
                    description: 'Indent named placeholder token',
                },
                13: {
                    input: input,
                    type: token_types_1.default.PLACEHOLDER,
                    regex: Tokenizer.createPlaceholderRegex(_this.cfg.namedPlaceholderTypes, Tokenizer.createStringPattern(_this.cfg.stringTypes)),
                    parseFunc: function (v) {
                        return Tokenizer.getEscapedPlaceholderKey({
                            key: v.slice(2, -1),
                            quoteChar: v.slice(-1),
                        });
                    },
                    description: 'String named placeholder token',
                },
                14: {
                    input: input,
                    type: token_types_1.default.PLACEHOLDER,
                    regex: Tokenizer.createPlaceholderRegex(_this.cfg.indexedPlaceholderTypes, '[0-9]*'),
                    parseFunc: function (v) { return v.slice(1); },
                    description: 'Index placeholder token',
                },
                15: {
                    input: input,
                    type: token_types_1.default.NUMBER,
                    regex: /^((-\s*)?[0-9]+(\.[0-9]+)?|0x[0-9a-fA-F]+|0b[01]+)\b/,
                },
                16: {
                    input: input,
                    type: token_types_1.default.RESERVED_TOPLEVEL,
                    regex: Tokenizer.getReservedWordToken(input, prev, Tokenizer.createMultiWordRegex(_this.cfg.reservedTopLevelWords)),
                },
                17: {
                    input: input,
                    type: token_types_1.default.RESERVED_NEWLINE,
                    regex: Tokenizer.getReservedWordToken(input, prev, Tokenizer.createMultiWordRegex(_this.cfg.reservedNewLineWords)),
                },
                18: {
                    input: input,
                    type: token_types_1.default.RESERVED,
                    regex: Tokenizer.getReservedWordToken(input, prev, Tokenizer.createMultiWordRegex(_this.cfg.reservedWords)),
                },
                19: {
                    input: input,
                    type: token_types_1.default.WORD,
                    regex: Tokenizer.createWordRegex(_this.cfg.specialWordChars),
                },
                20: {
                    input: input,
                    type: token_types_1.default.OPERATOR,
                    regex: /^(!=|<>|==|<=|>=|!<|!>|\|\||::|->>|->|~~\*|~~|!~~\*|!~~|~\*|!~\*|!~|.)/,
                },
            };
        };
        this.cfg = cfg;
    }
    Tokenizer.escapeParen = function (paren) {
        if (paren.length === 1) {
            // single punctuation character
            return lodash_1.escapeRegExp(paren);
        }
        else {
            // longer word
            return '\\b' + paren + '\\b';
        }
    };
    // This enables the following string patterns:
    // 1. backtick quoted string using `` to escape
    // 2. square bracket quoted string (SQL Server) using ]] to escape
    // 3. double quoted string using "" or \" to escape
    // 4. single quoted string using '' or \' to escape
    // 5. national character quoted string using N'' or N\' to escape
    Tokenizer.createStringPattern = function (types) {
        var patterns = {
            '``': '((`[^`]*($|`))+)',
            '[]': '((\\[[^\\]]*($|\\]))(\\][^\\]]*($|\\]))*)',
            '""': '(("[^"\\\\]*(?:\\\\.[^"\\\\]*)*("|$))+)',
            "''": "(('[^'\\\\]*(?:\\\\.[^'\\\\]*)*('|$))+)",
            "N''": "((N'[^N'\\\\]*(?:\\\\.[^N'\\\\]*)*('|$))+)",
        };
        return types.map(function (t) { return patterns[t]; }).join('|');
    };
    Tokenizer.createLineCommentRegex = function (ids) {
        return new RegExp("^((?:" + ids.map(function (id) { return lodash_1.escapeRegExp(id); }).join('|') + ").*?(?:\n|$))");
    };
    Tokenizer.createMultiWordRegex = function (words) {
        var pattern = words.join('|').replace(/ /g, '\\s+');
        return new RegExp("^(" + pattern + ")\\b", 'i');
    };
    Tokenizer.createWordRegex = function (chars) {
        return new RegExp("^([\\w" + chars.join('') + "]+)");
    };
    Tokenizer.createStringRegex = function (types) {
        return new RegExp('^(' + Tokenizer.createStringPattern(types) + ')');
    };
    Tokenizer.createParenRegex = function (parens) {
        return new RegExp('^(' + parens.map(function (p) { return Tokenizer.escapeParen(p); }).join('|') + ')', 'i');
    };
    Tokenizer.createPlaceholderRegex = function (types, pattern) {
        if (lodash_1.isEmpty(types)) {
            return /.^/;
        }
        var typesRegex = types.map(lodash_1.escapeRegExp).join('|');
        return new RegExp("^((?:" + typesRegex + ")(?:" + pattern + "))");
    };
    Tokenizer.getEscapedPlaceholderKey = function (_a) {
        var key = _a.key, quoteChar = _a.quoteChar;
        return key.replace(new RegExp(lodash_1.escapeRegExp('\\') + quoteChar, 'g'), quoteChar);
    };
    Tokenizer.getReservedWordToken = function (input, prev, regex) {
        // A reserved word cannot be preceded by a "."
        // this makes it so in "mytable.from", "from" is not considered a reserved word
        if (prev && prev.value && prev.value === '.') {
            return /.^/;
        }
        return regex;
    };
    Tokenizer.matchRegex = function (df) {
        var matches = df.input.match(df.regex);
        if (matches && matches.index === 0) {
            return __assign({ type: df.type, value: matches[0] }, (df.parseFunc && { key: df.parseFunc(matches[0]) }));
        }
        return false;
    };
    return Tokenizer;
}());
exports.default = Tokenizer;
//# sourceMappingURL=tokenizer.js.map